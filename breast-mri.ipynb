{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f773b2b1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-06-23T16:46:28.245626Z",
     "iopub.status.busy": "2023-06-23T16:46:28.244877Z",
     "iopub.status.idle": "2023-06-23T16:46:28.259740Z",
     "shell.execute_reply": "2023-06-23T16:46:28.258810Z"
    },
    "papermill": {
     "duration": 0.023279,
     "end_time": "2023-06-23T16:46:28.261980",
     "exception": false,
     "start_time": "2023-06-23T16:46:28.238701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d589dfef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:46:28.269364Z",
     "iopub.status.busy": "2023-06-23T16:46:28.269059Z",
     "iopub.status.idle": "2023-06-23T16:46:29.771930Z",
     "shell.execute_reply": "2023-06-23T16:46:29.770776Z"
    },
    "papermill": {
     "duration": 1.509503,
     "end_time": "2023-06-23T16:46:29.774613",
     "exception": false,
     "start_time": "2023-06-23T16:46:28.265110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Neural-Architecture-Search'...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 39, done.\u001b[K\r\n",
      "remote: Counting objects:   2% (1/39)\u001b[K\r",
      "remote: Counting objects:   5% (2/39)\u001b[K\r",
      "remote: Counting objects:   7% (3/39)\u001b[K\r",
      "remote: Counting objects:  10% (4/39)\u001b[K\r",
      "remote: Counting objects:  12% (5/39)\u001b[K\r",
      "remote: Counting objects:  15% (6/39)\u001b[K\r",
      "remote: Counting objects:  17% (7/39)\u001b[K\r",
      "remote: Counting objects:  20% (8/39)\u001b[K\r",
      "remote: Counting objects:  23% (9/39)\u001b[K\r",
      "remote: Counting objects:  25% (10/39)\u001b[K\r",
      "remote: Counting objects:  28% (11/39)\u001b[K\r",
      "remote: Counting objects:  30% (12/39)\u001b[K\r",
      "remote: Counting objects:  33% (13/39)\u001b[K\r",
      "remote: Counting objects:  35% (14/39)\u001b[K\r",
      "remote: Counting objects:  38% (15/39)\u001b[K\r",
      "remote: Counting objects:  41% (16/39)\u001b[K\r",
      "remote: Counting objects:  43% (17/39)\u001b[K\r",
      "remote: Counting objects:  46% (18/39)\u001b[K\r",
      "remote: Counting objects:  48% (19/39)\u001b[K\r",
      "remote: Counting objects:  51% (20/39)\u001b[K\r",
      "remote: Counting objects:  53% (21/39)\u001b[K\r",
      "remote: Counting objects:  56% (22/39)\u001b[K\r",
      "remote: Counting objects:  58% (23/39)\u001b[K\r",
      "remote: Counting objects:  61% (24/39)\u001b[K\r",
      "remote: Counting objects:  64% (25/39)\u001b[K\r",
      "remote: Counting objects:  66% (26/39)\u001b[K\r",
      "remote: Counting objects:  69% (27/39)\u001b[K\r",
      "remote: Counting objects:  71% (28/39)\u001b[K\r",
      "remote: Counting objects:  74% (29/39)\u001b[K\r",
      "remote: Counting objects:  76% (30/39)\u001b[K\r",
      "remote: Counting objects:  79% (31/39)\u001b[K\r",
      "remote: Counting objects:  82% (32/39)\u001b[K\r",
      "remote: Counting objects:  84% (33/39)\u001b[K\r",
      "remote: Counting objects:  87% (34/39)\u001b[K\r",
      "remote: Counting objects:  89% (35/39)\u001b[K\r",
      "remote: Counting objects:  92% (36/39)\u001b[K\r",
      "remote: Counting objects:  94% (37/39)\u001b[K\r",
      "remote: Counting objects:  97% (38/39)\u001b[K\r",
      "remote: Counting objects: 100% (39/39)\u001b[K\r",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\r\n",
      "remote: Compressing objects:   3% (1/31)\u001b[K\r",
      "remote: Compressing objects:   6% (2/31)\u001b[K\r",
      "remote: Compressing objects:   9% (3/31)\u001b[K\r",
      "remote: Compressing objects:  12% (4/31)\u001b[K\r",
      "remote: Compressing objects:  16% (5/31)\u001b[K\r",
      "remote: Compressing objects:  19% (6/31)\u001b[K\r",
      "remote: Compressing objects:  22% (7/31)\u001b[K\r",
      "remote: Compressing objects:  25% (8/31)\u001b[K\r",
      "remote: Compressing objects:  29% (9/31)\u001b[K\r",
      "remote: Compressing objects:  32% (10/31)\u001b[K\r",
      "remote: Compressing objects:  35% (11/31)\u001b[K\r",
      "remote: Compressing objects:  38% (12/31)\u001b[K\r",
      "remote: Compressing objects:  41% (13/31)\u001b[K\r",
      "remote: Compressing objects:  45% (14/31)\u001b[K\r",
      "remote: Compressing objects:  48% (15/31)\u001b[K\r",
      "remote: Compressing objects:  51% (16/31)\u001b[K\r",
      "remote: Compressing objects:  54% (17/31)\u001b[K\r",
      "remote: Compressing objects:  58% (18/31)\u001b[K\r",
      "remote: Compressing objects:  61% (19/31)\u001b[K\r",
      "remote: Compressing objects:  64% (20/31)\u001b[K\r",
      "remote: Compressing objects:  67% (21/31)\u001b[K\r",
      "remote: Compressing objects:  70% (22/31)\u001b[K\r",
      "remote: Compressing objects:  74% (23/31)\u001b[K\r",
      "remote: Compressing objects:  77% (24/31)\u001b[K\r",
      "remote: Compressing objects:  80% (25/31)\u001b[K\r",
      "remote: Compressing objects:  83% (26/31)\u001b[K\r",
      "remote: Compressing objects:  87% (27/31)\u001b[K\r",
      "remote: Compressing objects:  90% (28/31)\u001b[K\r",
      "remote: Compressing objects:  93% (29/31)\u001b[K\r",
      "remote: Compressing objects:  96% (30/31)\u001b[K\r",
      "remote: Compressing objects: 100% (31/31)\u001b[K\r",
      "remote: Compressing objects: 100% (31/31), done.\u001b[K\r\n",
      "Receiving objects:   2% (1/39)\r",
      "Receiving objects:   5% (2/39)\r",
      "Receiving objects:   7% (3/39)\r",
      "Receiving objects:  10% (4/39)\r",
      "Receiving objects:  12% (5/39)\r",
      "Receiving objects:  15% (6/39)\r",
      "Receiving objects:  17% (7/39)\r",
      "Receiving objects:  20% (8/39)\r",
      "Receiving objects:  23% (9/39)\r",
      "Receiving objects:  25% (10/39)\r",
      "Receiving objects:  28% (11/39)\r",
      "Receiving objects:  30% (12/39)\r",
      "Receiving objects:  33% (13/39)\r",
      "Receiving objects:  35% (14/39)\r",
      "Receiving objects:  38% (15/39)\r",
      "Receiving objects:  41% (16/39)\r",
      "Receiving objects:  43% (17/39)\r",
      "Receiving objects:  46% (18/39)\r",
      "Receiving objects:  48% (19/39)\r",
      "Receiving objects:  51% (20/39)\r",
      "Receiving objects:  53% (21/39)\r",
      "Receiving objects:  56% (22/39)\r",
      "Receiving objects:  58% (23/39)\r",
      "Receiving objects:  61% (24/39)\r",
      "Receiving objects:  64% (25/39)\r",
      "Receiving objects:  66% (26/39)\r",
      "Receiving objects:  69% (27/39)\r",
      "Receiving objects:  71% (28/39)\r",
      "Receiving objects:  74% (29/39)\r",
      "Receiving objects:  76% (30/39)\r",
      "Receiving objects:  79% (31/39)\r",
      "Receiving objects:  82% (32/39)\r",
      "Receiving objects:  84% (33/39)\r",
      "Receiving objects:  87% (34/39)\r",
      "Receiving objects:  89% (35/39)\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Total 39 (delta 8), reused 39 (delta 8), pack-reused 0\u001b[K\r\n",
      "Receiving objects:  92% (36/39)\r",
      "Receiving objects:  94% (37/39)\r",
      "Receiving objects:  97% (38/39)\r",
      "Receiving objects: 100% (39/39)\r",
      "Receiving objects: 100% (39/39), 34.46 KiB | 2.87 MiB/s, done.\r\n",
      "Resolving deltas:   0% (0/8)\r",
      "Resolving deltas:  12% (1/8)\r",
      "Resolving deltas:  25% (2/8)\r",
      "Resolving deltas:  37% (3/8)\r",
      "Resolving deltas:  50% (4/8)\r",
      "Resolving deltas:  62% (5/8)\r",
      "Resolving deltas:  75% (6/8)\r",
      "Resolving deltas:  87% (7/8)\r",
      "Resolving deltas: 100% (8/8)\r",
      "Resolving deltas: 100% (8/8), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/10isha/Neural-Architecture-Search.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cbf6bfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:46:29.783465Z",
     "iopub.status.busy": "2023-06-23T16:46:29.782577Z",
     "iopub.status.idle": "2023-06-23T16:46:29.790252Z",
     "shell.execute_reply": "2023-06-23T16:46:29.788861Z"
    },
    "papermill": {
     "duration": 0.01431,
     "end_time": "2023-06-23T16:46:29.792393",
     "exception": false,
     "start_time": "2023-06-23T16:46:29.778083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Neural-Architecture-Search\n"
     ]
    }
   ],
   "source": [
    "cd Neural-Architecture-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8017cd18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:46:29.800708Z",
     "iopub.status.busy": "2023-06-23T16:46:29.799863Z",
     "iopub.status.idle": "2023-06-23T16:46:30.822457Z",
     "shell.execute_reply": "2023-06-23T16:46:30.821256Z"
    },
    "papermill": {
     "duration": 1.029287,
     "end_time": "2023-06-23T16:46:30.824989",
     "exception": false,
     "start_time": "2023-06-23T16:46:29.795702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mNeural-Architecture-Search\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f676cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:46:30.834274Z",
     "iopub.status.busy": "2023-06-23T16:46:30.833348Z",
     "iopub.status.idle": "2023-06-23T16:46:30.840767Z",
     "shell.execute_reply": "2023-06-23T16:46:30.839265Z"
    },
    "papermill": {
     "duration": 0.014386,
     "end_time": "2023-06-23T16:46:30.842888",
     "exception": false,
     "start_time": "2023-06-23T16:46:30.828502",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Neural-Architecture-Search/Neural-Architecture-Search\n"
     ]
    }
   ],
   "source": [
    "cd Neural-Architecture-Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8288447e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:46:30.851320Z",
     "iopub.status.busy": "2023-06-23T16:46:30.850411Z",
     "iopub.status.idle": "2023-06-23T16:46:31.871617Z",
     "shell.execute_reply": "2023-06-23T16:46:31.870349Z"
    },
    "papermill": {
     "duration": 1.028224,
     "end_time": "2023-06-23T16:46:31.874343",
     "exception": false,
     "start_time": "2023-06-23T16:46:30.846119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m__pycache__\u001b[0m/  model.py         test.py          utils.py\r\n",
      "architect.py  model_search.py  train.py         visualize.py\r\n",
      "genotypes.py  operations.py    train_search.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53c3643d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-23T16:46:31.883599Z",
     "iopub.status.busy": "2023-06-23T16:46:31.883263Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-06-23T16:46:31.878296",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : eval-EXP-20230623-164636\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 108 36\r\n",
      "108 144 36\r\n",
      "144 144 36\r\n",
      "144 144 36\r\n",
      "144 144 36\r\n",
      "144 144 36\r\n",
      "144 144 72\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144 288 72\r\n",
      "288 288 72\r\n",
      "288 288 72\r\n",
      "288 288 72\r\n",
      "288 288 72\r\n",
      "288 288 72\r\n",
      "288 288 144\r\n",
      "288 576 144\r\n",
      "576 576 144\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576 576 144\r\n",
      "576 576 144\r\n",
      "576 576 144\r\n",
      "576 576 144\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /data/datasets/cifar-10/cifar-10-python.tar.gz\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                             | 0/170498071 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                           | 229376/170498071 [00:00<01:31, 1866681.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▎                        | 2424832/170498071 [00:00<00:13, 12649471.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█▍                      | 10289152/170498071 [00:00<00:03, 41294431.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|██▋                     | 19300352/170498071 [00:00<00:02, 59529460.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████                    | 28737536/170498071 [00:00<00:01, 71188098.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████▎                  | 38010880/170498071 [00:00<00:01, 78342316.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████▌                 | 46825472/170498071 [00:00<00:01, 81449226.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████▊                | 55738368/170498071 [00:00<00:01, 83841075.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|█████████               | 64520192/170498071 [00:00<00:01, 85032416.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████▎             | 73433088/170498071 [00:01<00:01, 85946237.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████▋            | 82935808/170498071 [00:01<00:00, 87874203.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|████████████▉           | 92110848/170498071 [00:01<00:00, 89023080.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████████████▋         | 101023744/170498071 [00:01<00:00, 88792549.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████▊        | 109936640/170498071 [00:01<00:00, 88662453.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████       | 118816768/170498071 [00:01<00:00, 88467622.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████▏     | 127696896/170498071 [00:01<00:00, 88369938.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████▍    | 137035776/170498071 [00:01<00:00, 89460398.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|███████████████████▋   | 146112512/170498071 [00:01<00:00, 89805905.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████▉  | 155123712/170498071 [00:01<00:00, 89512145.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|██████████████████████▏| 164102144/170498071 [00:02<00:00, 89489757.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████| 170498071/170498071 [00:02<00:00, 80664529.80it/s]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /data/datasets/cifar-10/cifar-10-python.tar.gz to /data/datasets/cifar-10\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\r\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\r\n",
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\r\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Neural-Architecture-Search/Neural-Architecture-Search/train.py:138: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\r\n",
      "  nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/Neural-Architecture-Search/Neural-Architecture-Search/train.py:160: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  input = Variable(input, volatile=True).cuda()\r\n",
      "/kaggle/working/Neural-Architecture-Search/Neural-Architecture-Search/train.py:161: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\r\n",
      "  target = Variable(target, volatile=True).cuda()\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-23T16:46:16.514276",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}